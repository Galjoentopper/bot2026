[DATA]
# Sequence length (lookback window) - research shows 60-100 works well
# Imperial College paper used 100 for movement prediction (best results)
# Updated to 100 based on research findings for better pattern recognition
# Options: 60 (faster, less context) or 100 (slower, more context)
sequence_length = 100
# Prediction horizon (steps ahead)
prediction_horizon = 1
# Base features from CSV
features = open,high,low,close,volume
# Target column for prediction
target = close
# Train/test split ratio (chronological)
# Updated to 0.6 for three-way split: 60% train / 20% validation / 20% test
# This prevents data leakage where prediction models trained on 80% are used
# to generate features for PPO training on the same 80% of data
# With 60/20/20 split: prediction models train on 60%, PPO trains on 60%,
# validates on 20%, and tests on 20% (models never see val/test data)
train_test_split = 0.6
# Whether to add technical indicators (RSI, MACD, Bollinger Bands, etc.)
use_technical_indicators = true

[MODEL]
# Hidden units per layer - RESEARCH-BASED OPTIMIZATION
# Imperial College paper used 100 units (matches research findings)
# Reduced from 512 to 100 to reduce overfitting and match research
# Options: 100 (research-based), 128, 256 (larger if needed)
units = 100
# Number of recurrent layers - RESEARCH-BASED
# Imperial College paper used 2 layers (matches research findings)
# Reduced from 4 to 2 to reduce overfitting
layers = 2
# Dropout rate for regularization - RESEARCH-BASED
# Increased from 0.15 to 0.25 to improve generalization and reduce overfitting
# Research papers use 0.2-0.3 for financial time series
dropout = 0.25
# Learning rate - RESEARCH-BASED
# Reduced from 0.0002 to 0.0001 for more stable training
learning_rate = 0.0001
# Weight decay (L2 regularization) - RESEARCH-BASED
# Standard value for financial time series to reduce overfitting
weight_decay = 0.00001
# Optimizer
optimizer = adam

[TRAINING]
# Batch size - RESEARCH-BASED OPTIMIZATION
# Imperial College paper used batch_size=64 for classification tasks
# Reduced from 1024 to 64 based on research findings for better generalization
# Smaller batches provide better gradient estimates and reduce overfitting
# Options: 64 (research-based), 128 (if training too slow)
batch_size = 64
# Maximum epochs
epochs = 150
# Early stopping patience - increased to allow more training
early_stopping_patience = 15
# Validation split from training data
validation_split = 0.1
# Use class weights for imbalanced classification
use_class_weights = true

[CLASSIFICATION]
# Smoothing window k - compare past k vs future k averages
# Imperial College paper tested k=20, 30, 50, 100
# k=20 achieved best accuracy (73.10%) in research
# Updated to 20 based on research findings (best result)
# Options: 20 (best from research), 30, 50, 100 (smoothest)
smoothing_k = 20
# Delta threshold: 'auto' calculates based on volatility
# Or set manual value like 0.0002
# Auto is usually best, but you can try manual values if needed
threshold_delta = auto
# Enable classification task
enable_classification = true

[DLSTM]
# Moving average window for trend decomposition (AvgPool1D pool_size)
# Smaller = more responsive, larger = smoother trends
# Imperial College paper used AvgPool (not Conv1D) for trend extraction
moving_average_window = 10
# Note: Both trend and remainder branches use full 'units' parameter from [MODEL] section
# This matches the research paper implementation (both branches use same capacity)

[ENSEMBLE]
# Enable ensemble training
enable_ensemble = false
# Models to include in ensemble
models = lstm,gru,bilstm,dlstm
# Voting method: soft or hard
voting = soft

[OUTPUT]
# Directory for saved models
models_dir = models
# Directory for scalers
scalers_dir = scalers
# Directory for results (plots, metrics, etc.)
results_dir = results
# Save training history
save_history = true
# Generate training plots
generate_plots = true

