{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PPO Trading Agent Training Notebook\n",
        "\n",
        "This notebook trains a PPO (Proximal Policy Optimization) agent for cryptocurrency trading.\n",
        "\n",
        "**Usage with Colab VS Code Extension:**\n",
        "1. Open this notebook in Cursor\n",
        "2. Select Kernel → Colab → New Colab Server\n",
        "3. Run cells sequentially\n",
        "\n",
        "**The agent uses your trained prediction models (LSTM/GRU/BiLSTM/DLSTM) as feature extractors.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 1: Setup & Mount Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "ENVIRONMENT CHECK\n",
            "==================================================\n",
            "\n",
            "1. Running on Colab: True\n",
            "   ✓ Colab environment detected\n",
            "\n",
            "2. /content exists: True\n",
            "\n",
            "3. Mounting Google Drive...\n",
            "   ✗ Error: mount failed\n"
          ]
        }
      ],
      "source": [
        "# DEBUG: Check what's in your Google Drive\n",
        "# Run this cell first to see where your files are located\n",
        "\n",
        "import os\n",
        "\n",
        "# Mount Drive first\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "except:\n",
        "    print(\"Not on Colab or Drive already mounted\")\n",
        "\n",
        "# List what's in the drive root\n",
        "print(\"Contents of /content/drive:\")\n",
        "for item in os.listdir('/content/drive'):\n",
        "    print(f\"  - {item}\")\n",
        "\n",
        "# Check MyDrive\n",
        "if os.path.exists('/content/drive/MyDrive'):\n",
        "    print(\"\\nContents of /content/drive/MyDrive:\")\n",
        "    for item in os.listdir('/content/drive/MyDrive')[:20]:  # First 20 items\n",
        "        print(f\"  - {item}\")\n",
        "    \n",
        "    # Check if Bot 2026 exists\n",
        "    if os.path.exists('/content/drive/MyDrive/Bot 2026'):\n",
        "        print(\"\\n✓ Found: /content/drive/MyDrive/Bot 2026\")\n",
        "    else:\n",
        "        print(\"\\n✗ NOT found: /content/drive/MyDrive/Bot 2026\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on Google Colab\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-551894756.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Not in Colab environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on Google Colab\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-551894756.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Not in Colab environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Setup environment (handles Colab detection, Drive mounting, path setup)\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Check if running on Colab\n",
        "IS_COLAB = 'COLAB_GPU' in os.environ or os.path.exists('/content')\n",
        "\n",
        "if IS_COLAB:\n",
        "    print(\"Running on Google Colab\")\n",
        "    \n",
        "    # Mount Google Drive\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "    except ImportError:\n",
        "        pass  # Not in Colab environment\n",
        "    \n",
        "    # Find the Bot 2026 folder (supports multiple Drive locations)\n",
        "    possible_paths = [\n",
        "        '/content/drive/MyDrive/Bot 2026',\n",
        "        '/content/drive/Othercomputers/Mijn laptop/Bot 2026',\n",
        "        '/content/drive/Othercomputers/My Laptop/Bot 2026',\n",
        "    ]\n",
        "    \n",
        "    PROJECT_PATH = None\n",
        "    for path in possible_paths:\n",
        "        if os.path.exists(path):\n",
        "            PROJECT_PATH = path\n",
        "            print(f\"Found project at: {path}\")\n",
        "            break\n",
        "    \n",
        "    if PROJECT_PATH is None:\n",
        "        # Try to find it dynamically\n",
        "        print(\"Searching for Bot 2026 folder...\")\n",
        "        for root, dirs, files in os.walk('/content/drive'):\n",
        "            if 'Bot 2026' in dirs:\n",
        "                PROJECT_PATH = os.path.join(root, 'Bot 2026')\n",
        "                print(f\"Found project at: {PROJECT_PATH}\")\n",
        "                break\n",
        "            # Limit search depth\n",
        "            if root.count(os.sep) > 5:\n",
        "                break\n",
        "    \n",
        "    if PROJECT_PATH is None:\n",
        "        raise FileNotFoundError(\"Could not find 'Bot 2026' folder in Google Drive!\")\n",
        "    \n",
        "    PPO_PATH = f'{PROJECT_PATH}/PPO approach'\n",
        "    \n",
        "    # Add to Python path\n",
        "    sys.path.insert(0, PROJECT_PATH)\n",
        "    sys.path.insert(0, PPO_PATH)\n",
        "    \n",
        "    # Change working directory\n",
        "    os.chdir(PPO_PATH)\n",
        "else:\n",
        "    print(\"Running locally\")\n",
        "    PROJECT_PATH = os.path.dirname(os.getcwd())\n",
        "    PPO_PATH = os.getcwd()\n",
        "\n",
        "print(f\"Project path: {PROJECT_PATH}\")\n",
        "print(f\"PPO path: {PPO_PATH}\")\n",
        "\n",
        "# Now import our modules\n",
        "from colab_utils import setup_environment, get_project_path, get_ppo_path\n",
        "env_info = setup_environment()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (only needed on Colab)\n",
        "if IS_COLAB:\n",
        "    import subprocess\n",
        "    subprocess.run([\"pip\", \"install\", \"stable-baselines3\", \"gymnasium\", \"tensorboard\", \"shimmy\", \"-q\"])\n",
        "    print(\"Dependencies installed!\")\n",
        "else:\n",
        "    print(\"Running locally - ensure dependencies are installed in your venv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3: Verify GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(\"GPU Check:\")\n",
        "print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"  GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"  WARNING: No GPU detected. Training will be slower.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4: Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "CONFIG = {\n",
        "    # Dataset\n",
        "    'dataset': 'ETH-EUR_1H_20240101-20251231',  # Change to your dataset\n",
        "    \n",
        "    # Prediction model\n",
        "    'prediction_model': 'ensemble',  # 'lstm', 'gru', 'bilstm', 'dlstm', or 'ensemble'\n",
        "    \n",
        "    # Training\n",
        "    'total_timesteps': 500000,  # Increase for better results (1M+ recommended)\n",
        "    'checkpoint_freq': 50000,\n",
        "    \n",
        "    # Environment\n",
        "    'transaction_cost': 0.0025,  # 0.25% Bitvavo fee\n",
        "    'initial_capital': 10000,\n",
        "    'max_episode_steps': 1000,\n",
        "}\n",
        "\n",
        "print(\"Configuration:\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5: Load Prediction Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from prediction_wrapper import load_ensemble, load_prediction_model, get_available_models\n",
        "\n",
        "# Show available models\n",
        "print(\"Available models:\")\n",
        "for model in get_available_models():\n",
        "    print(f\"  - {model}\")\n",
        "\n",
        "# Load prediction models\n",
        "print(f\"\\nLoading prediction models for: {CONFIG['dataset']}\")\n",
        "\n",
        "if CONFIG['prediction_model'] == 'ensemble':\n",
        "    prediction_models = load_ensemble(CONFIG['dataset'])\n",
        "else:\n",
        "    prediction_models = load_prediction_model(CONFIG['prediction_model'], CONFIG['dataset'])\n",
        "\n",
        "if prediction_models.loaded:\n",
        "    print(\"\\n✓ Prediction models loaded successfully!\")\n",
        "else:\n",
        "    print(\"\\n⚠ Warning: Could not load prediction models.\")\n",
        "    print(\"  Training will proceed without prediction features.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 6: Create Trading Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from trading_env import TradingEnv\n",
        "from colab_utils import get_datasets_path\n",
        "from pathlib import Path\n",
        "\n",
        "# Find dataset\n",
        "datasets_path = get_datasets_path()\n",
        "dataset_files = list(datasets_path.glob(f\"*{CONFIG['dataset']}*\"))\n",
        "\n",
        "if not dataset_files:\n",
        "    print(f\"ERROR: Dataset not found: {CONFIG['dataset']}\")\n",
        "    print(\"Available datasets:\")\n",
        "    for f in datasets_path.glob(\"*.csv\"):\n",
        "        print(f\"  - {f.name}\")\n",
        "else:\n",
        "    dataset_path = dataset_files[0]\n",
        "    print(f\"Using dataset: {dataset_path.name}\")\n",
        "    \n",
        "    # Create training environment\n",
        "    train_env = TradingEnv(\n",
        "        dataset_path=dataset_path,\n",
        "        prediction_models=prediction_models if prediction_models.loaded else None,\n",
        "        transaction_cost=CONFIG['transaction_cost'],\n",
        "        initial_capital=CONFIG['initial_capital'],\n",
        "        train_mode=True,\n",
        "        train_split=0.8,\n",
        "        max_episode_steps=CONFIG['max_episode_steps'],\n",
        "    )\n",
        "    \n",
        "    # Create evaluation environment\n",
        "    eval_env = TradingEnv(\n",
        "        dataset_path=dataset_path,\n",
        "        prediction_models=prediction_models if prediction_models.loaded else None,\n",
        "        transaction_cost=CONFIG['transaction_cost'],\n",
        "        initial_capital=CONFIG['initial_capital'],\n",
        "        train_mode=False,  # Use test data\n",
        "        train_split=0.8,\n",
        "        max_episode_steps=CONFIG['max_episode_steps'],\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n✓ Environments created!\")\n",
        "    print(f\"  Training steps available: {train_env.data_end_idx - train_env.data_start_idx}\")\n",
        "    print(f\"  Evaluation steps available: {eval_env.data_end_idx - eval_env.data_start_idx}\")\n",
        "    print(f\"  Action space: {train_env.action_space}\")\n",
        "    print(f\"  Observation space: {train_env.observation_space}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 7: Train PPO Agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ppo_trading_agent import train_with_checkpoints\n",
        "from colab_utils import get_checkpoints_path\n",
        "\n",
        "# Set checkpoint path\n",
        "checkpoint_path = get_checkpoints_path() / f\"{CONFIG['prediction_model']}_{CONFIG['dataset']}\"\n",
        "print(f\"Checkpoints will be saved to: {checkpoint_path}\")\n",
        "\n",
        "# Train with checkpointing (for Colab timeout recovery)\n",
        "print(f\"\\nStarting training for {CONFIG['total_timesteps']:,} timesteps...\")\n",
        "print(\"Progress will be saved automatically.\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "model = train_with_checkpoints(\n",
        "    env=train_env,\n",
        "    total_timesteps=CONFIG['total_timesteps'],\n",
        "    checkpoint_freq=CONFIG['checkpoint_freq'],\n",
        "    checkpoint_path=checkpoint_path,\n",
        "    eval_env=eval_env,\n",
        "    eval_freq=10000,\n",
        "    n_eval_episodes=3,\n",
        "    resume=True,  # Resume from checkpoint if exists\n",
        "    device='auto',\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 8: Evaluate Trained Agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from evaluate_ppo import evaluate_agent\n",
        "import numpy as np\n",
        "\n",
        "print(\"Evaluating trained agent...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Evaluate on test data\n",
        "results = evaluate_agent(model, eval_env, n_episodes=10, deterministic=True)\n",
        "\n",
        "print(\"\\nEvaluation Results:\")\n",
        "print(f\"  Mean Reward: {results['mean_reward']:.2f} ± {results['std_reward']:.2f}\")\n",
        "print(f\"  Mean Return: {results.get('mean_return_pct', 0):.2f}%\")\n",
        "print(f\"  Episodes: {results['n_episodes']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 9: Save Final Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from colab_utils import get_ppo_models_path\n",
        "\n",
        "# Save final model\n",
        "models_path = get_ppo_models_path()\n",
        "model_name = f\"ppo_{CONFIG['prediction_model']}_{CONFIG['dataset']}.zip\"\n",
        "final_model_path = models_path / model_name\n",
        "\n",
        "model.save(str(final_model_path))\n",
        "print(f\"\\n✓ Model saved to: {final_model_path}\")\n",
        "\n",
        "# Verify save\n",
        "if final_model_path.exists():\n",
        "    size_mb = final_model_path.stat().st_size / 1e6\n",
        "    print(f\"  Size: {size_mb:.2f} MB\")\n",
        "else:\n",
        "    print(\"  ERROR: Save failed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 10: Cleanup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Close environments\n",
        "train_env.close()\n",
        "eval_env.close()\n",
        "\n",
        "print(\"Training complete!\")\n",
        "print(f\"\\nNext steps:\")\n",
        "print(f\"  1. Model saved at: {final_model_path}\")\n",
        "print(f\"  2. Run evaluate_ppo.py for detailed analysis\")\n",
        "print(f\"  3. Use visualize_results.py for plots\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
